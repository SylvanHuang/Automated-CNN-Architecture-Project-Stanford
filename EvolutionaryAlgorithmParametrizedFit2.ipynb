{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python STL imports\n",
    "import collections\n",
    "from contextlib import redirect_stdout\n",
    "import csv\n",
    "import math\n",
    "import os\n",
    "import pydot\n",
    "import random as rand\n",
    "from random import sample\n",
    "import timeit\n",
    "\n",
    "# CNN framework imports\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils import plot_model\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import SVG\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mnist_dataset(train_sample = 2000, test_sample = 500):\n",
    "    \"\"\"Helper to generate dataset for the tests\n",
    "    \n",
    "    Args:\n",
    "        train_sample: how many samples for training set\n",
    "        test_sample: how many samples for the test set\n",
    "    \n",
    "    Returns:\n",
    "        Tuple t, where t[0] is the train set, t[1] is the validation set and t[2] is the test set\n",
    "    \"\"\"\n",
    "    \n",
    "    classes = 10\n",
    "    width = 28\n",
    "    height = 28\n",
    "    channels = 1\n",
    "\n",
    "    (X_train, Y_train), (X_test, Y_test)= fashion_mnist.load_data()\n",
    "\n",
    "    K.set_image_data_format(\"channels_last\")\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], width, height, channels) #.astype('float32') / 255 \n",
    "    X_test = X_test.reshape(X_test.shape[0], width, height, channels) #.astype('float32') / 255\n",
    "    Y_train = to_categorical(Y_train)\n",
    "    Y_test = to_categorical(Y_test)\n",
    "    X_train = X_train[:int(train_sample)]\n",
    "    Y_train = Y_train[:int(train_sample)]\n",
    "    X_test = X_test[:int(test_sample)]\n",
    "    Y_test = Y_test[:int(test_sample)]\n",
    "\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1, shuffle= True)\n",
    "\n",
    "    #dataset = ((X_train.astype(\"float32\")/255, Y_train), (X_val.astype(\"float32\")/255, Y_val), (X_test.astype(\"float32\")/255, Y_test))\n",
    "    dataset = ((X_train, Y_train), (X_val, Y_val), (X_test, Y_test))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Genome:\n",
    "    \"\"\"Class to manage constructing networks and constructing new sample networks.\n",
    "    \n",
    "    The structure is that all networks in this code are defined by a sequence. A sequence\n",
    "    is a list of integers where each member is a choice. The index in sequences indicates what type of\n",
    "    layer (dense, convolutional, pooling) and what choice in that layer is being described.\n",
    "    \n",
    "    Given a sequence, _Network() can produce a model.\n",
    "    \n",
    "    Please see |self.conv_block|, |self.dense_block|, and |self.pooling_block| to see the choices available\n",
    "    per layer.\n",
    "    \n",
    "    Note: as of python3.7, the insertion order in a  dictionary is preserved. I.e. iterating over the keys\n",
    "    below is guaranteed to iterate in the same order as the keys are declared on the dictionaries.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_conv=6, max_dense=2, max_filters =128, input_shape = (28,28,1),\n",
    "                 classes =10, max_pooling= 0,  activation = 'relu',\n",
    "                 max_filter_size =5, max_dense_units = 1024):\n",
    "        \"\"\"Initialize Genome class.\n",
    "        \n",
    "        Args:\n",
    "            max_conv: the max number of convolutional layers\n",
    "            max_dense: the max number of dense layers\n",
    "            max_filters: the max number of filters\n",
    "            input_shape: image input shape\n",
    "            classes: the number of classes to classify\n",
    "            max_pooling: the maximum number of pooling layers\n",
    "            activation: activation method to pass to Activation layer\n",
    "            max_filter_size: max size of filters\n",
    "            max_dense_units: max number of dense units\n",
    "        \"\"\"\n",
    "        self.max_conv = max_conv\n",
    "        self.max_dense = max_dense\n",
    "        self.max_pooling =max_pooling\n",
    "        self.max_filters = max_filters \n",
    "        self.input_shape = input_shape\n",
    "        self.classes = classes\n",
    "        self.activation = activation\n",
    "        self.max_filter_size = max_filter_size\n",
    "        self.max_dense_units = max_dense_units\n",
    "        self.history_fitness_sequences = []\n",
    "        self.mutation_prob = 0.05\n",
    "        \n",
    "        #dictionaries with all possible parameters of CNN layers:\n",
    "        self.conv_block = { 'on_off': [0,1],\n",
    "                            'n_filters': [2**i for i in range(2, int(math.log(self.max_filters, 2))+1)],\n",
    "                            'filter_sizes': [3 + 2*i for i in range(0, (max_filter_size-1)//2)],   \n",
    "                            'batch_norm': [0,1],\n",
    "                            'drop_out': [0, 0.2, 0.3, 0.4, 0.5]\n",
    "                          }\n",
    "        \n",
    "        self.dense_block = { 'on_off': [0,1],\n",
    "                             'units': [2**i for i in range(2, int(math.log(self.max_dense_units, 2))+1)] ,\n",
    "                             'batch_norm': [0,1],\n",
    "                             'drop_out': [0, 0.2, 0.3, 0.4, 0.5]\n",
    "                           }\n",
    "        \n",
    "        self.pooling_block = {'on_off': [0,1]\n",
    "                             }\n",
    "        \n",
    "        # genome sizes: \n",
    "        self.len_conv_block = len(self.conv_block) # number of genes assigned to conv_block\n",
    "        self.len_dense_block = len(self.dense_block)  # number of genes assigned to dense_block\n",
    "        self.len_pooling_block = len(self.pooling_block) # number of genes assigned to pooling_block\n",
    "        \n",
    "        #total length of genome sequence: \n",
    "        self.genome_length = self.max_conv * self.len_conv_block + self.max_dense *self.len_dense_block +\\\n",
    "                             self.max_conv *self.len_pooling_block\n",
    "            \n",
    "        #length of genome sequence assigned to convolutional_layer_blocks:     \n",
    "        self.genome_conv_length = self.max_conv * self.len_conv_block\n",
    "        \n",
    "        #length of genome sequence assigned to dense_layer_blocks:\n",
    "        self.genome_dense_length = self.max_dense *self.len_dense_block\n",
    "        \n",
    "\n",
    "    def _genome_initialization(self, method='random'):\n",
    "        \"\"\"Helper to initialize a genome.\n",
    "        \n",
    "        Args:\n",
    "            method: str, random, min, or max. Depending on the choice, each choice in the\n",
    "                    genome is either min, max, or random. See class description for choices.\n",
    "        \n",
    "        Returns:\n",
    "            sequence, list of values for each genome choice to construct network\n",
    "        \"\"\"\n",
    "        if method not in ['random', 'min', 'max']:\n",
    "            raise Exception('Method %s unknown.' % method)\n",
    "        if method == 'random':\n",
    "            fn = np.random.choice\n",
    "        elif method == 'min':\n",
    "            fn = min\n",
    "        elif method == 'max':\n",
    "            fn = max\n",
    "        individual=[] # empty list to store population \n",
    "        #first construct conv layers genes sequence\n",
    "        for i in range(self.max_conv):\n",
    "            for key in self.conv_block:\n",
    "                individual.append(fn(self.conv_block[key]))\n",
    "            for key in self.pooling_block:\n",
    "                individual.append(fn(self.pooling_block[key]))\n",
    "\n",
    "        #second constract dense layers genes sequence\n",
    "        for i in range(self.max_dense):\n",
    "            for key in self.dense_block:\n",
    "                individual.append(fn(self.dense_block[key]))\n",
    "        #assure that we have at least one conv layer:\n",
    "        individual[0] = 1\n",
    "        \n",
    "        return individual\n",
    "            \n",
    "                     \n",
    "    def _Network(self, individual):\n",
    "        \"\"\"Generate a network from |individual|.\n",
    "        \n",
    "        Args:\n",
    "            individual: list of integers, template for each network later to construct a network.\n",
    "        Returns:\n",
    "            keras Model object constructed from template\n",
    "        \"\"\"\n",
    "        \n",
    "        X_input = Input(self.input_shape)\n",
    "        X= X_input\n",
    "\n",
    "        idx = 0\n",
    "        for _ in range(self.max_conv):\n",
    "            if individual[idx] ==1:\n",
    "                n_filters = int(individual[idx+1])\n",
    "                filter_size = int(individual[idx+2])\n",
    "                X= Conv2D(n_filters, (filter_size, filter_size), padding ='same')(X)\n",
    "                if individual[idx+3] ==1:  \n",
    "                    X = BatchNormalization()(X)\n",
    "                X = Activation(self.activation)(X)  \n",
    "                if individual[idx+4] > 0 :  \n",
    "                    X = Dropout(individual[idx+5])(X)\n",
    "                \n",
    "            idx += self.len_conv_block\n",
    "            \n",
    "            if individual[idx] ==1:\n",
    "                if X.shape[1] > 7: \n",
    "                    X = MaxPooling2D((2, 2))(X)\n",
    "            idx += self.len_pooling_block                      \n",
    "            \n",
    "        X = Flatten()(X)  \n",
    "        \n",
    "        for _ in range(self.max_dense):\n",
    "            if individual[idx] ==1:\n",
    "                X = Dense(int(individual[idx+1]), activation= self.activation)(X)\n",
    "                \n",
    "                if individual[idx+2] ==1:  \n",
    "                    X = BatchNormalization()(X)\n",
    "                X = Activation(self.activation)(X)   \n",
    "\n",
    "                if individual[idx+3] > 0 :  \n",
    "                    X = Dropout(individual[idx+3])(X)\n",
    "                \n",
    "            idx+= self.len_dense_block    \n",
    "            \n",
    "        X = Dense(self.classes, activation='softmax')(X)\n",
    "        \n",
    "        model = Model(inputs = X_input, outputs = X)\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    \n",
    "    def _crossover(self, sequences):\n",
    "        \"\"\"Randomly cross over two sequences.\n",
    "        \n",
    "        Randomly pick an index and create a new sequence out of all elements from the first sequence up\n",
    "        to and excluding the index, and all members from the other sequences after that.\n",
    "        \n",
    "        Args:\n",
    "            sequence: two member list of model template sequences\n",
    "            \n",
    "        Returns:\n",
    "            list, model template sequence after crossing over the two sequences in |sequences|\n",
    "        \"\"\"\n",
    "        \n",
    "        cross_sequence =[]\n",
    "        \n",
    "        idx = rand.randint(0, len(sequences[0]))\n",
    "        \n",
    "        for i in range(idx):\n",
    "            cross_sequence.append(sequences[0][i])\n",
    "            \n",
    "        for i in range(idx, len(sequences[0])):\n",
    "            cross_sequence.append(sequences[1][i])\n",
    "             \n",
    "        #print(self.cross_sequence)\n",
    "        return cross_sequence \n",
    "    \n",
    "    def _mutate(self, sequence, num_mutations = None):\n",
    "        \"\"\"Mutate |sequence| |num_mutations| times.\n",
    "        \n",
    "        Args:\n",
    "            individual: list of integers, template for each network later to construct a network\n",
    "            num_mutations: number of mutations to perform, or None. If None, a random number\n",
    "                           of mutations between 0 and 5 is chosen.\n",
    "        \n",
    "        Returns:\n",
    "            mutated_sequence: list, model template sequence after mutations\n",
    "        \"\"\"\n",
    "        \n",
    "        if num_mutations == None:\n",
    "            max_mutations = int(np.random.choice(5))\n",
    "        else:\n",
    "            max_mutations = int(num_mutations)\n",
    "        #print('seq', sequence)    \n",
    "        mutated_sequence = sequence\n",
    "        for i in range(max_mutations):\n",
    "            #print(i, max_mutations)\n",
    "            #print(len(sequence) - 1)\n",
    "            idx = int(np.random.choice(range(1, len(sequence) - 1)))\n",
    "            if idx < self.max_conv*(self.len_pooling_block + self.len_conv_block):\n",
    "                length = self.len_pooling_block + self.len_conv_block\n",
    "                if idx%length < 5:\n",
    "                    mutated_sequence[idx] = np.random.choice(self.conv_block[list(self.conv_block)[idx%length]])\n",
    "                else:\n",
    "                    mutated_sequence[idx] = np.random.choice(self.pooling_block['on_off'])\n",
    "\n",
    "            else:\n",
    "                idx = idx - self.max_conv*(self.len_pooling_block + self.len_conv_block)\n",
    "                mutated_sequence[idx] = np.random.choice(self.conv_block[list(self.conv_block)[idx%4]])\n",
    "                \n",
    "        return mutated_sequence\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Algorithm:\n",
    "    \"\"\"Class to run the algorithm and collect statistics.\"\"\"\n",
    "    \n",
    "    def __init__(self, dataset, epochs=2, batch_size=200, verbose=1, iterations = 10,\n",
    "                 population_size =10, sample_strategy = 'best'):\n",
    "        \"\"\"Initialize algorithm class.\n",
    "        \n",
    "        Args:\n",
    "            dataset: dataset to use\n",
    "            epochs: epochs to run over dataset\n",
    "            batch_size: batch size for training and validation\n",
    "            verbose: 0 indicates silent, 1 indicates progress bar, 2 indicates one line per epoch\n",
    "                     (keras.models.Model)\n",
    "            iterations: number of iterations to run the evolutionary algorithm for\n",
    "            population_size: number of sequences in one population \n",
    "            sample_strategy: str, sampling strategy to find the next population from a previous population\n",
    "        \"\"\"\n",
    "        \n",
    "        (self.X_train, self.Y_train), (self.X_val, self.Y_val), (self.X_test, self.Y_test) = dataset\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.verbose = verbose\n",
    "        self.population_size = population_size\n",
    "        self.iter_best_accuracy = []\n",
    "        self.iter_best_time = []\n",
    "        self.iter_best_sequence = []\n",
    "        self.iter_best_params = []\n",
    "        self.iterations = iterations\n",
    "        self.mu_acc = []\n",
    "        self.std_acc = []\n",
    "        self.start = True\n",
    "        self.full_sequence = []\n",
    "        self.full_acc = []\n",
    "        self.full_time = []\n",
    "        self.full_params = []\n",
    "        self. sample_strategy= sample_strategy\n",
    "        \n",
    "        \n",
    "    def _individual_fitness(self, individual):\n",
    "        \"\"\"Evaluate sequence |individual|.\n",
    "        \n",
    "        Generate a Model from |indidividual|, train it, and evaluate it before reporting the results\n",
    "        \n",
    "        Args:\n",
    "            individual: list, model template sequence\n",
    "        \n",
    "        Returns:\n",
    "             tuple t, where t[0] is the sequence to generate the network\n",
    "                            t[1] is the fitness accuracy(percentage)\n",
    "                            t[2] is the time in seconds to evaluate the model\n",
    "                            t[3] is the the number of parameters in the model\n",
    "        \"\"\"\n",
    "        \n",
    "        model = Genome()._Network(individual)  \n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        es =  EarlyStopping(monitor= 'val_loss', patience=1)\n",
    "        model.fit(self.X_train, self.Y_train, epochs = self.epochs, batch_size = self.batch_size, \n",
    "                  validation_data =(self.X_val, self.Y_val), callbacks=[es], verbose=self.verbose) \n",
    "        \n",
    "        start = timeit.default_timer()\n",
    "        preds = model.evaluate(self.X_test, self.Y_test)\n",
    "        stop = timeit.default_timer()\n",
    "        \n",
    "        # This cleans out the tensorflow graph before creating a new one. As this code generates many models\n",
    "        # and then discards them, this is critical to stay within memory bounds and not explode.\n",
    "        # Needless to say: do not remove.\n",
    "        K.clear_session()\n",
    "              \n",
    "        fitness_acc = preds[1]\n",
    "        fitness_time = stop-start\n",
    "        \n",
    "        return individual, fitness_acc, fitness_time, model.count_params()\n",
    "    \n",
    "    def _population_fitness(self, population, best_history, full_history):\n",
    "        \"\"\"Given |population|, evaluate each member, and append to |best_history| and |full_history|.\n",
    "        \n",
    "        Args:\n",
    "            population: list of sequences to evalute\n",
    "            best_history: a tuple bh, where bh[0] is a list of the best accuracy per iteration\n",
    "                                            bh[1] is a list of the runtimes per iteration\n",
    "                                            bh[2] is a list of the number of params of the best performing network per iteration\n",
    "                                            bh[3] is a list of actual sequences of highest performing networks per iteration\n",
    "                                            bh[4] is the mean accuracy per iteration\n",
    "                                            bh[5] is the standard deviation of the accuracy per iteration\n",
    "                          best_history can be though of a matrix as well.\n",
    "            full_history: a tuple fh, where fh[0] is a list of the accuracy per experiment (iterations * population size)\n",
    "                                            fh[1] is a list of the runtimes per experiment (iterations * population size) \n",
    "                                            fh[2] is a list of the number of params per experiment (iterations * population size)\n",
    "                                            fh[3] is a list of the sequences for each experiment\n",
    "                                            \n",
    "        Returns:\n",
    "            A tuple t, where t[0] is the a fitness tuple for |population|\n",
    "                                t[0][0] contains a list of accuracy per experiment\n",
    "                                t[0][1] contains a list of validation time per experiment\n",
    "                                t[0][2] contains a list of number of parameters per experiment\n",
    "                                t[0][3] contains a list of sequences samples\n",
    "                              t[1] is |best_history| expanded with the best result from |population|\n",
    "                              t[2] is |full_history| expanded with all the results from |population| \n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        self.fitness_sequence = []\n",
    "        self.fitness_acc = []\n",
    "        self.fitness_time = []\n",
    "        self.fitness_params = []\n",
    "        self.mu_acc = [] \n",
    "        self.std_acc = []\n",
    "        \n",
    "        (self.iter_best_accuracy, self.iter_best_time, self.iter_best_params, self.iter_best_sequence, self.mu_acc, self.std_acc) = best_history\n",
    "        (self.full_acc, self.full_time, self.full_params, self.full_sequence) = full_history\n",
    "        \n",
    "        for individual in tqdm_notebook(population):\n",
    "            \n",
    "            individual, fitness_acc, fitness_time, fitness_params  = self._individual_fitness(individual)\n",
    "            \n",
    "            self.fitness_acc.append(fitness_acc)\n",
    "            self.fitness_time.append(fitness_time)\n",
    "            self.fitness_params.append(fitness_params)\n",
    "            self.fitness_sequence.append(individual)\n",
    "  \n",
    "            \n",
    "        fitness = (self.fitness_acc, self.fitness_time, self.fitness_params, self.fitness_sequence)\n",
    "        \n",
    "        for full, run in [(self.full_sequence, self.fitness_sequence),\n",
    "                          (self.full_acc, self.fitness_acc),\n",
    "                          (self.full_time, self.fitness_time),\n",
    "                          (self.full_params, self.fitness_params)]:\n",
    "            full.extend(run)\n",
    "            \n",
    "        full_history =  (self.full_acc, self.full_time, self.full_params, self.full_sequence)\n",
    "        \n",
    "\n",
    "        idx = self.fitness_acc.index(max(self.fitness_acc))\n",
    "        self.iter_best_accuracy.append(self.fitness_acc[idx])\n",
    "        self.iter_best_time.append(self.fitness_time[idx])\n",
    "        self.iter_best_params.append(self.fitness_params[idx])\n",
    "        self.iter_best_sequence.append(self.fitness_sequence[idx])\n",
    "        self.mu_acc.append(np.mean(self.fitness_acc))\n",
    "        self.std_acc.append(np.std(self.fitness_acc))\n",
    "            \n",
    "        best_history = (self.iter_best_accuracy, self.iter_best_time, self.iter_best_params, self.iter_best_sequence, self.mu_acc, self.std_acc)\n",
    "        \n",
    "        return fitness, best_history, full_history\n",
    "\n",
    "    def _main(self, initial_population, min_time, max_time):\n",
    "        \"\"\"Main function to run the algorithm.\n",
    "        \n",
    "        Will run algorithm for |self.iterations| iterations before returning all information about\n",
    "        the run.\n",
    "        \n",
    "        Args:\n",
    "            initial_population: list of sequences to start the experiment with\n",
    "            min_time: prediction time for a minimal (smallest) network on given hardware\n",
    "            max_time: prediction time on maximal (biggest) network on given hardware\n",
    "            \n",
    "        Returns:\n",
    "            tuple t, where t[0] is best_history, matrix // see _population_fitness() for details on shape and elements\n",
    "                           t[1] is best_accuracy, accuracy of highest accuracy sequence\n",
    "                           t[2] is best_run_time, validation time of highest accuracy sequence\n",
    "                           t[3] is best_params, number of parameters for highest accuracy sequence\n",
    "                           t[4] is the keras.models.Model object for the best performing sequence\n",
    "                           t[5] is the full_history, matrix // see _population_fitness() for details on shape and elements\n",
    "                           t[6] is the total run time for the algorithm\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"Iteration:\", 0)\n",
    "        \n",
    "        best_history = (self.iter_best_accuracy, self.iter_best_time, self.iter_best_params, self.iter_best_sequence, self.mu_acc, self.std_acc)\n",
    "        full_history= (self.full_acc, self.full_time, self.full_params, self.full_sequence)\n",
    "        \n",
    "        self.population = initial_population\n",
    "        \n",
    "        fitness, best_history, full_history = self._population_fitness(self.population, best_history, full_history)\n",
    "        \n",
    "        start = timeit.default_timer()\n",
    "        for i in tqdm_notebook(range(1, self.iterations)):\n",
    "            print(\"Iteration:\", i)\n",
    "            self.population = Population(self.population_size)._offspring(fitness, best_history, full_history, self.sample_strategy, min_time, max_time )\n",
    "            fitness, best_history, full_history = self._population_fitness(self.population, best_history, full_history)\n",
    "            #print(best_history)\n",
    "            # Turn fitness_time into an array to extract information\n",
    "            time_array = np.array(fitness[1])\n",
    "            global_time_stats[self.sample_strategy].append((time_array.mean(), time_array.std()))\n",
    "            \n",
    "        stop = timeit.default_timer()\n",
    "        best_accuracy, best_run_time, best_params, best_model =  Population(self.population_size)._get_final_statistics(best_history)\n",
    "        total_run_time = (stop-start)/60\n",
    "        \n",
    "        return best_history, best_accuracy, best_run_time, best_params, best_model, full_history, total_run_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Population:\n",
    "    \"\"\"Class to handle populations.\n",
    "    \n",
    "    It provides tools to generate random populations, pick a new population given a previous (or all previous)\n",
    "    population(s), and get final statistics for the best sequence found throughout the algorithm.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Default weights for fitness functions considering more than just accuracy.\n",
    "    # Please look at _offspring() below to see the fitness functions\n",
    "    w_accuracy = 1\n",
    "    w_time = -1\n",
    "    w_params = -1\n",
    "    \n",
    "    def __init__(self, size):\n",
    "        \"\"\"Initialize the population class.\n",
    "        \n",
    "        Args:\n",
    "            size: number of sequences in one population\n",
    "        \"\"\"\n",
    "        \n",
    "        self.size = size\n",
    "        self.population = []\n",
    "        self.prob_crossover = 0.5\n",
    "        self.prob_mutation = 0.5\n",
    "        self.iter_best_accuracy = []\n",
    "        self.iter_run_time = []\n",
    "        self.iter_best_sequences = []\n",
    "        self.mu_acc = []\n",
    "        self.std_acc = []\n",
    "        \n",
    "    @classmethod\n",
    "    def set_weights(cls, w_accuracy = 1, w_time = -1, w_params = -1):\n",
    "        \"\"\"Helper method for weights.\n",
    "        \n",
    "        Below in fitness functions you will find that |w_accuracy|, |w_time| and |w_params| are \n",
    "        used to decide how important each of those elements is for a fitness. This class function\n",
    "        sets those weights to experiment with bigger or smaller impacts.\n",
    "        \n",
    "        Note: not all fitness functions use all parameters, please take a look below in _offspring()\n",
    "        \n",
    "        Args:\n",
    "            w_accuracy: weight that the accuracy of a sequence should have on fitness functions\n",
    "            w_time: weight that the predict time should have fitness functions\n",
    "            w_params: weight that log of number of params should have on fitness functions\n",
    "        \"\"\"\n",
    "        cls.w_accuracy = w_accuracy\n",
    "        cls.w_time = w_time\n",
    "        cls.w_params = w_params\n",
    "        \n",
    "    def _population_initialization(self):\n",
    "        \"\"\"Append random sequences to |self.population| for |self.size| iterations for initial population.\"\"\"\n",
    "        while len(self.population) < self.size:\n",
    "            self.population.append(Genome()._genome_initialization())\n",
    "    \n",
    "        return self.population\n",
    "    \n",
    "    \n",
    "    def _offspring(self, fitness, best_history, full_history, sample_strategy = 'random', min_time=0, max_time=1):\n",
    "        \"\"\"Generate an offsprign population.\n",
    "        \n",
    "        Note on gibbs functions: In order to facilitate debugging, all gibbs based strategies will append\n",
    "        to a file called results/[experiment_name]_[sample_strategy]_weights.txt.\n",
    "        Every entry in that file has the list of gibbs weights and full accuraries.\n",
    "        \n",
    "        \n",
    "        Args:\n",
    "            fitness: matrix, // see _population_fitness() for details on shape and elements\n",
    "            best_history: matrix // see _population_fitness() for details on shape and elements \n",
    "            full_history: matrix // see _population_fitness() for details on shape and elements\n",
    "            sample_strategy: a valid sampling strategy, currently supported strategies are:\n",
    "                             random\n",
    "                             tournament\n",
    "                             tournament_epsilon\n",
    "                             gibbs\n",
    "                             gibbs_epsilon\n",
    "                             tournament_gibbs\n",
    "                             tournament_fit2\n",
    "                             tournament_epsilon_fit2\n",
    "                             tournament_gibbs_epsilon_fit2\n",
    "                             tournament_fit2(norm)\n",
    "                             tournament_epsilon_fit2(norm)\n",
    "                             tournament_gibbs_epsilon_fit2(norm)\n",
    "                             tournament_fit3 # is not used in this poject and is provided as example for future research\n",
    "                             // see below in the code for details on each strategy. There are comments\n",
    "            min_time: validation time on a minimal network on running hardware, used for normalization\n",
    "            max_time: validation time on a maximal network on running hardware, used for normalization\n",
    "        \n",
    "        Returns:\n",
    "            self.offspring: a new list of sequences\n",
    "        \"\"\"\n",
    "        \n",
    "        self.offspring = []\n",
    "        \n",
    "        (self.fitness_acc, self.fitness_time, self.fitness_params, self.fitness_sequences) = fitness\n",
    "        (self.iter_best_accuracy, self.iter_run_time, self.iter_best_params, self.iter_best_sequence, self.mu_acc, self.std_acc) = best_history\n",
    "        \n",
    "        \n",
    "        #get two best individuals from population fitness:\n",
    "        top2_acc, top2_run_time, top2_params, top2_sequence = self._best_individuals()\n",
    "        \n",
    "        best_acc = max(top2_acc)\n",
    "        idx = top2_acc.index(best_acc)\n",
    "        best_run_time = top2_run_time[idx]\n",
    "        best_sequence = top2_sequence[idx]\n",
    "        best_params = top2_params[idx]\n",
    "        mu_acc = np.mean(self.fitness_acc)\n",
    "        std_acc = np.std(self.fitness_acc)\n",
    "\n",
    "        print(\"Best accuracy for iteration: {0:3f}, with prediction time: {1:3f}\".format(best_acc,best_run_time))\n",
    "        print(\"Mean accuracy for iteration: {0:3f}, std: {1:3f}\".format(mu_acc, std_acc))      \n",
    "        \n",
    "        # Used below in the gibbs methods.\n",
    "        self.full_acc, self.full_time, self.full_params, self.full_sequence = full_history\n",
    "        \n",
    "        if sample_strategy == 'random':\n",
    "            # Randomly pick all elements for the new population.\n",
    "            for _ in range(self.size):\n",
    "                self.offspring.append(Genome()._genome_initialization()) \n",
    "    \n",
    "        elif sample_strategy == 'tournament':   \n",
    "            #cross two best models:\n",
    "            self.offspring.append(Genome()._crossover(top2_sequence))  \n",
    "            \n",
    "            for _ in range(self.size-1):\n",
    "                sequences = []\n",
    "                # randomly choose 2 models, then chosse best from this two models and append it to population. \n",
    "                # Repeat two times                   \n",
    "                for _ in range(2):\n",
    "                    sequences.append(self._best_individual(self._random_choice()))  \n",
    "                    #cross two chosen models: \n",
    "                self.offspring.append(Genome()._crossover(sequences))\n",
    "                \n",
    "            # randomly mutate\n",
    "            for i in range(1, len(self.offspring)):\n",
    "                self.offspring[i] = Genome()._mutate(self.offspring[i], num_mutations = 3) \n",
    "        \n",
    "            \n",
    "        if sample_strategy == 'tournament_epsilon':   \n",
    "            \n",
    "            #cross two best models:\n",
    "            self.offspring.append(Genome()._crossover(top2_sequence))  \n",
    "            \n",
    "            for _ in range(self.size-3):\n",
    "                sequences = []\n",
    "                # randomly choose 2 models, then chosse best from this two models and append it to population. \n",
    "                # Repeat two times                   \n",
    "                for _ in range(2):\n",
    "                    sequences.append(self._best_individual(self._random_choice()))  \n",
    "                    #cross two chosen models: \n",
    "                self.offspring.append(Genome()._crossover(sequences))\n",
    "\n",
    "            #add two fully mutated sequence: \n",
    "            for _ in range(2):\n",
    "                self.offspring.append(Genome()._genome_initialization()) \n",
    "                \n",
    "            # randomly mutate\n",
    "            for i in range(1, len(self.offspring)):\n",
    "                self.offspring[i] = Genome()._mutate(self.offspring[i], num_mutations = 3)        \n",
    "        \n",
    "\n",
    "        elif sample_strategy == 'gibbs':\n",
    "            # Choose sequences from previously seen sequences in a sampling fashion, using their\n",
    "            # normalized accuracy as a probability of being chosen.\n",
    "            self.gibbs_weights = [i/sum(self.full_acc) for i in self.full_acc]\n",
    "\n",
    "            for _ in range(self.size):\n",
    "                self.offspring.append(self._gibbs_sampling()) \n",
    "\n",
    "            # randomly mutate\n",
    "            for i in range(len(self.offspring)):\n",
    "                self.offspring[i] = Genome()._mutate(self.offspring[i], num_mutations = 3)   \n",
    "                \n",
    "                \n",
    "        elif sample_strategy == 'gibbs_epsilon':   \n",
    "            # Choose all but 2 sequences from previously seen sequences in a sampling fashion, using their\n",
    "            # normalized accuracy as a probability of being chosen.\n",
    "            # Choose the remaining two sequences randomly.\n",
    "            self.gibbs_weights = [i/sum(self.full_acc) for i in self.full_acc]\n",
    "\n",
    "            for _ in range(self.size-2):\n",
    "                self.offspring.append(self._gibbs_sampling()) \n",
    "                \n",
    "            #add two fully mutated sequence: \n",
    "            for _ in range(2):\n",
    "                self.offspring.append(Genome()._genome_initialization()) \n",
    "                \n",
    "            # randomly mutate\n",
    "            for i in range(len(self.offspring)):\n",
    "                self.offspring[i] = Genome()._mutate(self.offspring[i], num_mutations = 3)   \n",
    "                \n",
    "        elif sample_strategy == 'tournament_gibbs': \n",
    "            # Choose sequences from previously seen sequences in a sampling fashion, using their\n",
    "            # normalized accuracy as a probability of being chosen.\n",
    "            # For each output sequence, choose two sequences as described above and cross them\n",
    "            self.gibbs_weights = [i/sum(self.full_acc) for i in self.full_acc]\n",
    "\n",
    "            for _ in range(self.size):\n",
    "                sequences = []\n",
    "                for _ in range(2):\n",
    "                    sequences.append(self._gibbs_sampling()) \n",
    "                #cross two chosen models:\n",
    "                self.offspring.append(Genome()._crossover(sequences))\n",
    "            # randomly mutate\n",
    "            for i in range(len(self.offspring)):\n",
    "                self.offspring[i] = Genome()._mutate(self.offspring[i], num_mutations = 3)          \n",
    "        \n",
    "        elif sample_strategy =='tournament_fit2':\n",
    "            # Choose top 2 sequences using fit2 (accuracy and validation time) as fitness function\n",
    "            self.fit = [(Population.w_accuracy * acc + (Population.w_time * time))\n",
    "                        for acc, time in zip(self.fitness_acc, self.fitness_time)]\n",
    "        \n",
    "            print('self.fit', self.fit)\n",
    "            \n",
    "            top2_fit = sorted(self.fit)[-2:]\n",
    "            \n",
    "            top2_sequence = [self.fitness_sequences[self.fit.index(f)] for f in top2_fit]\n",
    "            \n",
    "            #print(idx, self.best_accuracy, self.best_sequence)\n",
    "            self.offspring.append(Genome()._mutate(self.fitness_sequences[idx], num_mutations = 2))  \n",
    "\n",
    "            #cross two best models:\n",
    "            self.offspring.append(Genome()._crossover(top2_sequence))  \n",
    "            \n",
    "            for _ in range(self.size-1):\n",
    "                sequences = []\n",
    "                # randomly choose 2 models, then chosse best from this two models and append it to population. \n",
    "                # Repeat two times                   \n",
    "                for _ in range(2):\n",
    "                    sequences.append(self._best_individual(self._random_choice(metric = 'fit')))  \n",
    "                    #cross two chosen models: \n",
    "                self.offspring.append(Genome()._crossover(sequences))  \n",
    "\n",
    "            # randomly mutate\n",
    "            for i in range(1, len(self.offspring)):\n",
    "                self.offspring[i] = Genome()._mutate(self.offspring[i], num_mutations = 3) \n",
    "        \n",
    "        \n",
    "        elif sample_strategy=='tournament_epsilon_fit2':\n",
    "            # Choose top 2 sequences using fit2 (accuracy and validation time) as fitness function\n",
    "            # Add two fully random sequences.\n",
    "            self.fit = [(Population.w_accuracy * acc + (Population.w_time*time))\n",
    "                        for acc, time in zip(self.fitness_acc, self.fitness_time)]\n",
    "        \n",
    "            top2_fit = sorted(self.fit)[-2:]\n",
    "            \n",
    "            top2_sequence = [self.fitness_sequences[self.fit.index(f)] for f in top2_fit]\n",
    "            \n",
    "            #print(idx, self.best_accuracy, self.best_sequence)\n",
    "            self.offspring.append(Genome()._mutate(self.fitness_sequences[idx], num_mutations = 2))  \n",
    "\n",
    "            #cross two best models:\n",
    "            self.offspring.append(Genome()._crossover(top2_sequence))  \n",
    "            \n",
    "            for _ in range(self.size-3):\n",
    "                sequences = []\n",
    "                # randomly choose 2 models, then chosse best from this two models and append it to population. \n",
    "                # Repeat two times                   \n",
    "                for _ in range(2):\n",
    "                    sequences.append(self._best_individual(self._random_choice(metric = 'fit')))  \n",
    "                    #cross two chosen models: \n",
    "                self.offspring.append(Genome()._crossover(sequences))  \n",
    "            \n",
    "            #add two fully mutated sequence: \n",
    "            for _ in range(2):\n",
    "                self.offspring.append(Genome()._genome_initialization())   \n",
    "            \n",
    "            # randomly mutate\n",
    "            for i in range(1, len(self.offspring)):\n",
    "                self.offspring[i] = Genome()._mutate(self.offspring[i], num_mutations = 3)\n",
    "                \n",
    "        elif sample_strategy == 'tournament_gibbs_epsilon_fit2':  \n",
    "            # Choose sequences from previously seen sequences in a sampling fashion, using their\n",
    "            # normalized fit2 (accuracy and validation time) as a probability of being chosen.\n",
    "            # For each but 2 output sequences, choose two sequences as described above and cross them\n",
    "            # Pick 2 random output sequences\n",
    "            self.gibbs_weights = [max((Population.w_accuracy * acc +  (time* Population.w_time)),0)\n",
    "                        for acc, time in zip(self.full_acc, self.full_time)]\n",
    "            self.gibbs_weights = [i/sum(self.gibbs_weights) for i in self.gibbs_weights]\n",
    "            \n",
    "            for _ in range(self.size-2):\n",
    "                sequences = []\n",
    "                for _ in range(2):\n",
    "                    sequences.append(self._gibbs_sampling()) \n",
    "                #cross two chosen models:\n",
    "                self.offspring.append(Genome()._crossover(sequences))\n",
    "                \n",
    "            #add two fully mutated sequence: \n",
    "            for _ in range(2):\n",
    "                self.offspring.append(Genome()._genome_initialization())     \n",
    "                \n",
    "            # randomly mutate\n",
    "            for i in range(len(self.offspring)):\n",
    "                self.offspring[i] = Genome()._mutate(self.offspring[i], num_mutations = 3) \n",
    "\n",
    "\n",
    "        elif sample_strategy=='tournament_fit2(norm)':\n",
    "            # Choose top 2 sequences using fit2 (accuracy and validation time) as fitness function\n",
    "            # The validation_time is normalized against |min_time| and |max_time|.\n",
    "            self.fit = [(Population.w_accuracy * acc + (Population.w_time*(time-min_time)/(max_time-min_time)))\n",
    "                        for acc, time in zip(self.fitness_acc, self.fitness_time)]\n",
    "            \n",
    "            print('self.fit', self.fit)\n",
    "        \n",
    "            top2_fit = sorted(self.fit)[-2:]\n",
    "            \n",
    "            top2_sequence = [self.fitness_sequences[self.fit.index(f)] for f in top2_fit]\n",
    "            \n",
    "            #print(idx, self.best_accuracy, self.best_sequence)\n",
    "            self.offspring.append(Genome()._mutate(self.fitness_sequences[idx], num_mutations = 2))  \n",
    "\n",
    "            #cross two best models:\n",
    "            self.offspring.append(Genome()._crossover(top2_sequence))  \n",
    "            \n",
    "            for _ in range(self.size-1):\n",
    "                sequences = []\n",
    "                # randomly choose 2 models, then chosse best from this two models and append it to population. \n",
    "                # Repeat two times                   \n",
    "                for _ in range(2):\n",
    "                    sequences.append(self._best_individual(self._random_choice(metric = 'fit')))  \n",
    "                    #cross two chosen models: \n",
    "                self.offspring.append(Genome()._crossover(sequences))  \n",
    "\n",
    "            # randomly mutate\n",
    "            for i in range(1, len(self.offspring)):\n",
    "                self.offspring[i] = Genome()._mutate(self.offspring[i], num_mutations = 3)\n",
    "        \n",
    "        elif sample_strategy=='tournament_epsilon_fit2(norm)':\n",
    "            # Choose top 2 sequences using fit2 (accuracy and validation time) as fitness function\n",
    "            # The validation_time is normalized against |min_time| and |max_time|.\n",
    "            # Add two fully random sequences.\n",
    "            self.fit = [(Population.w_accuracy * acc + (Population.w_time*(time-min_time)/(max_time-min_time)))\n",
    "                        for acc, time in zip(self.fitness_acc, self.fitness_time)]\n",
    "        \n",
    "            top2_fit = sorted(self.fit)[-2:]\n",
    "            \n",
    "            top2_sequence = [self.fitness_sequences[self.fit.index(f)] for f in top2_fit]\n",
    "            \n",
    "            #print(idx, self.best_accuracy, self.best_sequence)\n",
    "            self.offspring.append(Genome()._mutate(self.fitness_sequences[idx], num_mutations = 2))  \n",
    "\n",
    "            #cross two best models:\n",
    "            self.offspring.append(Genome()._crossover(top2_sequence))  \n",
    "            \n",
    "            for _ in range(self.size-3):\n",
    "                sequences = []\n",
    "                # randomly choose 2 models, then chosse best from this two models and append it to population. \n",
    "                # Repeat two times                   \n",
    "                for _ in range(2):\n",
    "                    sequences.append(self._best_individual(self._random_choice(metric = 'fit')))  \n",
    "                    #cross two chosen models: \n",
    "                self.offspring.append(Genome()._crossover(sequences))  \n",
    "            \n",
    "            #add two fully mutated sequence: \n",
    "            for _ in range(2):\n",
    "                self.offspring.append(Genome()._genome_initialization())   \n",
    "            \n",
    "            # randomly mutate\n",
    "            for i in range(1, len(self.offspring)):\n",
    "                self.offspring[i] = Genome()._mutate(self.offspring[i], num_mutations = 3)\n",
    "                \n",
    "        elif sample_strategy == 'tournament_gibbs_epsilon_fit2(norm)':  \n",
    "            # Choose sequences from previously seen sequences in a sampling fashion, using their\n",
    "            # normalized fit2 (accuracy and validation time) as a probability of being chosen.\n",
    "            # The validation_time is normalized against |min_time| and |max_time|.\n",
    "            # For each but 2 output sequences, choose two sequences as described above and cross them\n",
    "            # Pick 2 random output sequences\n",
    "            self.gibbs_weights = [max((Population.w_accuracy * acc + ((time- min_time)/(max_time-min_time) * Population.w_time)),0)\n",
    "                        for acc, time in zip(self.full_acc, self.full_time)]\n",
    "            self.gibbs_weights = [i/sum(self.gibbs_weights) for i in self.gibbs_weights]\n",
    "            \n",
    "            for _ in range(self.size-2):\n",
    "                sequences = []\n",
    "                for _ in range(2):\n",
    "                    sequences.append(self._gibbs_sampling()) \n",
    "                #cross two chosen models:\n",
    "                self.offspring.append(Genome()._crossover(sequences))\n",
    "                \n",
    "            #add two fully mutated sequence: \n",
    "            for _ in range(2):\n",
    "                self.offspring.append(Genome()._genome_initialization())     \n",
    "                \n",
    "            # randomly mutate\n",
    "            for i in range(len(self.offspring)):\n",
    "                self.offspring[i] = Genome()._mutate(self.offspring[i], num_mutations = 3)      \n",
    "                \n",
    "        elif sample_strategy =='tournament_fit3':\n",
    "            # Choose top 2 sequences using fit3 (accuracy and number of parameters) as fitness function\n",
    "            self.fit = [(Population.w_accuracy * acc + (Population.w_params * param))\n",
    "                        for acc, param in zip(self.fitness_acc, self.fitness_params)]\n",
    "        \n",
    "            print('self.fit', self.fit)\n",
    "            \n",
    "            top2_fit = sorted(self.fit)[-2:]\n",
    "            \n",
    "            top2_sequence = [self.fitness_sequences[self.fit.index(f)] for f in top2_fit]\n",
    "            \n",
    "            #print(idx, self.best_accuracy, self.best_sequence)\n",
    "            self.offspring.append(Genome()._mutate(self.fitness_sequences[idx], num_mutations = 2))  \n",
    "\n",
    "            #cross two best models:\n",
    "            self.offspring.append(Genome()._crossover(top2_sequence))  \n",
    "            \n",
    "            for _ in range(self.size-1):\n",
    "                sequences = []\n",
    "                # randomly choose 2 models, then chosse best from this two models and append it to population. \n",
    "                # Repeat two times                   \n",
    "                for _ in range(2):\n",
    "                    sequences.append(self._best_individual(self._random_choice(metric = 'fit')))  \n",
    "                    #cross two chosen models: \n",
    "                self.offspring.append(Genome()._crossover(sequences))  \n",
    "\n",
    "            # randomly mutate\n",
    "            for i in range(1, len(self.offspring)):\n",
    "                self.offspring[i] = Genome()._mutate(self.offspring[i], num_mutations = 3)          \n",
    "                \n",
    "        \n",
    "        if 'gibbs' in sample_strategy:\n",
    "            weight_f = 'results/%s_%s_weights.txt' % (experiment_name, str(sample_strategy))\n",
    "            with open(weight_f, 'a') as f:\n",
    "                f.write('full_acc:\\n %s\\n' % str(self.full_acc))\n",
    "                f.write('gibbs_weights:\\n %s\\n' % str(self.gibbs_weights))\n",
    "                f.write('-----------------\\n')\n",
    "                \n",
    "        return self.offspring\n",
    "          \n",
    "    def _best_individuals(self):\n",
    "        \"\"\"Find information about the best two sequences in a set.\n",
    "        \n",
    "        Returns: tuple t, where t[0] contains the best accuracy\n",
    "                                t[1] contains the runtime of that sequence\n",
    "                                t[2] contains the number of parameters of that sequence\n",
    "                                t[3] contains the actual sequence\n",
    "                 each entry has two members, and they are in sync, so t[0][1] belongs with t[1][1]\n",
    "        \"\"\"\n",
    "        run_time = []\n",
    "        parameters = []\n",
    "        best_sequences = []\n",
    "        best_accuracy = sorted(self.fitness_acc)[-2:] \n",
    "        for accuracy in best_accuracy:\n",
    "            idx = self.fitness_acc.index(accuracy)                   \n",
    "            run_time.append(self.fitness_time[idx])\n",
    "            parameters.append(self.fitness_params[idx])\n",
    "            best_sequences.append(self.fitness_sequences[idx])\n",
    "        \n",
    "        return best_accuracy, run_time, parameters, best_sequences                               \n",
    "    \n",
    "    def _random_choice(self, metric = 'acc'):\n",
    "        \"\"\"Randomly choose two sequences.\n",
    "        \n",
    "        Args:\n",
    "            metric: one of 'acc' or 'fit', which metric to report about the random sequence chosen to caller\n",
    "        \n",
    "        Returns:\n",
    "            tuple t, where t[0] is a list of sequences and t[1] is the corresponding fitness metric\n",
    "                t is always size 2\n",
    "        \"\"\"\n",
    "        sequences = [] \n",
    "        fit = []\n",
    "        for _ in range(2):                       \n",
    "            idx = int(rand.uniform(0, self.size - 1))\n",
    "            sequences.append(self.fitness_sequences[idx])\n",
    "            \n",
    "            if metric == 'acc':\n",
    "                fit.append(self.fitness_acc[idx])\n",
    "            elif metric == 'fit':\n",
    "                fit.append(self.fit[idx])\n",
    "                \n",
    "        return (sequences, fit)\n",
    "    \n",
    "    \n",
    "    def _gibbs_sampling(self):\n",
    "        \"\"\"Sample one sequence using |self.gibbs_weights|.\n",
    "        \n",
    "        Note: make sure that the code calling this properly initialized |self.gibbs_weights|\n",
    "        \n",
    "        Returns:\n",
    "            a sequence from |self.full_sequence|\n",
    "        \"\"\"\n",
    "        idx = int(np.random.choice(range(0, len(self.full_acc)), 1, p = self.gibbs_weights))\n",
    "        gibbs_sequence = self.full_sequence[idx]\n",
    "\n",
    "        return gibbs_sequence\n",
    "    \n",
    "                               \n",
    "    def _best_individual(self, rand_sequences):\n",
    "        \"\"\"Find the highest accuracy sequence in |rand_sequences|.\n",
    "        \n",
    "        Args:\n",
    "            rand_sequences: list of sequences\n",
    "            \n",
    "        Returns:\n",
    "            best_sequence, sequence in |rand_sequences| with highest accuracy\n",
    "        \"\"\"\n",
    "        (sequences, accuracy) = rand_sequences\n",
    "        idx = accuracy.index(max(accuracy))\n",
    "        best_sequence = sequences[idx]\n",
    "        \n",
    "        return best_sequence     \n",
    "    \n",
    "    def _get_final_statistics(self, best_history):\n",
    "        \"\"\"Extract the statistics out of |best_history|.\n",
    "        \n",
    "        Args:\n",
    "            best_history: tuple of tuples, please see population_fitness() for shape and meaning\n",
    "        \n",
    "        Returns:\n",
    "            tuple t, where t[0] is the best accuracy overall a sequence produced\n",
    "                           t[1] is the runtime of that sequence\n",
    "                           t[2] is the number of parameters of that sequence\n",
    "                           t[3] is the keras.models.Model object corresponding to that best sequence\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        (self.iter_best_accuracy, self.iter_run_time, self.iter_best_params, self.iter_best_sequences, self.mu_acc, self.std_acc) = best_history\n",
    "        best_accuracy = max(self.iter_best_accuracy)\n",
    "        idx =  self.iter_best_accuracy.index(best_accuracy)    \n",
    "        best_sequence = self.iter_best_sequences[idx]\n",
    "        best_run_time = self.iter_run_time[idx]\n",
    "        best_params = self.iter_best_params[idx]\n",
    "        best_model = Genome()._Network(best_sequence)\n",
    "        \n",
    "        return best_accuracy, best_run_time, best_params, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _initialize_population(experiment_name = '', population_size = 10):\n",
    "    \"\"\"Helper to initialize population.\n",
    "    \n",
    "    For some experiments one wants to reuse the same initial population and for others not.\n",
    "    If a population file already exists with experiment_name, the population is loaded,\n",
    "    otherwise a new population for the experiment is generated and cached in the experiment's\n",
    "    initial population file.\n",
    "    \n",
    "    Args:\n",
    "        experiment_name: name of the experiment population\n",
    "        population_size: number of sequences in a population\n",
    "    \n",
    "    Returns:\n",
    "        initial_population: list of sequences, either from file or newly generated\n",
    "    \"\"\"\n",
    "    \n",
    "    population_f = os.path.join('results', '%s_initial.csv' % experiment_name)\n",
    "    \n",
    "    if os.path.exists(population_f):\n",
    "        print('Reusing existing population %s' % experiment_name)\n",
    "        return _get_initial_population(population_f)\n",
    "    print('Population %s not defined yet. Creating it now' % experiment_name)\n",
    "    \n",
    "    # No luck, the population doesn't exist yet.\n",
    "    initial_population = Population(population_size)._population_initialization()\n",
    "\n",
    "    # Cache the population for future use here.\n",
    "    with open(population_f, 'w') as f:\n",
    "        wr = csv.writer(f, delimiter=',')\n",
    "        wr.writerows(initial_population)     \n",
    "                 \n",
    "    return initial_population       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_initial_population(population_file):\n",
    "    \"\"\"Load caches population from |population_file|.\n",
    "    \n",
    "    Note: This assumes the caller checked that the file exists.\n",
    "    \n",
    "    Args:\n",
    "        population_file: filename of the population csv file\n",
    "    \n",
    "    Returns:\n",
    "        initial_population, list of sequences found at |population_file|\n",
    "    \"\"\"\n",
    "    with open(population_file, 'r') as f:\n",
    "        reader = csv.reader(f, delimiter=',')\n",
    "        initial_population = list(reader)\n",
    "\n",
    "    for i in range(len(initial_population)):\n",
    "        for j in range(len(initial_population[0])):\n",
    "            initial_population[i][j] = float(initial_population[i][j])       \n",
    "            \n",
    "            \n",
    "    return initial_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run(initial_population , dataset, epochs = 15, \n",
    "         batch_size = 200, verbose= 0, iterations = 20,population_size = 10, \n",
    "         sample_strategy ='random', experiment_name = '5', only_time_bound=False):\n",
    "    \"\"\"Run the CNN search.\n",
    "    \n",
    "    Args:\n",
    "        initial_population: list of sequences to serve as initial population\n",
    "        dataset: dataset to use for search\n",
    "        epochs: epochs to run over dataset\n",
    "        batch_size: batch size for training and validation\n",
    "        verbose: 0 indicates silent, 1 indicates progress bar, 2 indicates one line per epoch\n",
    "                 (keras.models.Model)\n",
    "        iterations: number of iterations to run the evolutionary algorithm for\n",
    "        population_size: number of sequences in one population\n",
    "        sample_strategy: str, sampling strategy to find the next population from a previous population\n",
    "        experiment_name: name for the experiment, to tag output files with\n",
    "        only_time_bound: if true, only the validation time for largest and smallest network will print before\n",
    "                         exiting (experimental, to see validation time spread on given hardware)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    algorithm = Algorithm(dataset=dataset, epochs=epochs,\\\n",
    "                          batch_size=batch_size, \n",
    "                          verbose= verbose, \\\n",
    "                          iterations = iterations, \\\n",
    "                          population_size = population_size, \\\n",
    "                          sample_strategy = sample_strategy)\n",
    "    \n",
    "    \n",
    "    max_res = algorithm._individual_fitness(Genome()._genome_initialization(method='max'))\n",
    "    min_res  = algorithm._individual_fitness(Genome()._genome_initialization(method='min'))\n",
    "    max_acc, max_time = max_res[1], max_res[2]\n",
    "    min_acc, min_time = min_res[1], min_res[2]\n",
    "    \n",
    "    print('The min network predict accuracy: {0:3f}, with prediction time: {1:3f}'.format(min_acc, min_time))\n",
    "    print('The max network predict accuracy: {0:3f}, with prediction time: {1:3f}'.format(max_acc, max_time))\n",
    "    if only_time_bound:\n",
    "        return min_time, max_time\n",
    "\n",
    "    best_history_top2, best_accuracy_top2, best_run_time_top2, best_params_top2, best_model_top2,full_history_top2, total_run_time_top2= algorithm._main(initial_population, min_time, max_time )\n",
    "    accuracy_top2, run_time_top2, params_top2, sequence_top2, mu_acc_top2, std_acc_top2 = best_history_top2\n",
    "    full_acc_top2, full_time_top2, full_params_top2, full_sequence_top2= full_history_top2\n",
    "\n",
    "    # Note: all files that this outputs are in results, with this base template, meaning that outputs\n",
    "    # are tagged by sample strategy and experiment name.\n",
    "    results_base_template = 'results/%s_%s' % (experiment_name, str(sample_strategy))\n",
    "    name_summary = '%s_%s' % (results_base_template, 'summary.txt')\n",
    "    # Print and store the summary text. The summary text is pretty much just a summary of the best error,\n",
    "    # and prediction time, total train time, and a summary of the model that produced those values.\n",
    "    with open(name_summary, 'w') as f:\n",
    "        with redirect_stdout(f):\n",
    "            print(\"Best error: {0:3f}, with prediction time: {1:3f}\".format(best_accuracy_top2,best_run_time_top2))\n",
    "            print(\"Total train time: {0:2f}\".format(total_run_time_top2), \"min\")\n",
    "            print(\"Best model:\", best_model_top2.summary())\n",
    "    with open(name_summary, 'r') as f:\n",
    "        print(f.read())\n",
    "\n",
    "    # Plot accuracy over iterations\n",
    "    plt.ylabel('Test Accuracy')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.title('Evolution Startegy with '+str(sample_strategy)+' Sampling')    \n",
    "    plt.errorbar(range(iterations), mu_acc_top2, std_acc_top2,  marker='^')\n",
    "    plt.plot(range(iterations), accuracy_top2)\n",
    "    plt.legend(['Best accuracy', 'Mean statistic'])\n",
    "    plt.grid()\n",
    "    name_plot = '%s.%s' % (results_base_template, 'svg')\n",
    "    plt.savefig(name_plot, format='svg')\n",
    "    plt.show()\n",
    "    \n",
    "    # Dump results into a csv to make analysis with other tools easier later\n",
    "    name_res = '%s_%s'% (results_base_template, 'results.csv')\n",
    "    # Save model as a .h5 file to reuse later if desired\n",
    "    name_model = '%s.%s' % (results_base_template, 'h5')\n",
    "    \n",
    "    top2 = (best_history_top2, full_history_top2, [best_accuracy_top2, best_run_time_top2, best_params_top2, total_run_time_top2])\n",
    "    with open(name_res,\"w\") as f:\n",
    "        wr = csv.writer(f, delimiter=',')\n",
    "        wr.writerows(top2)\n",
    "\n",
    "    best_model_top2.save(name_model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# List of parameters to change manually or have a config file overwrite using papermill.\n",
    "# Essentially, these parameters will be passed into _run() below, and allow for one cell to control\n",
    "# different experiments in the same notebook.\n",
    "# The papermill module inputs a cell below this cell with overwrites based on the configuration file\n",
    "# provided so that parametrized experiments can be run.\n",
    "\n",
    "# Note that experiment_name's first 4 characters are used to define the initial population. So\n",
    "# a set of experiments that wants to share the same initial population should all start with\n",
    "# the same first four characters, while a two experiments that wish to have (likely) distinct\n",
    "# initial populations should have distinct first 4 characters.\n",
    "\n",
    "# ---- Again, summarizing ---- \n",
    "# If you wish to run this in an interactive notebook, this is the place to change what experiment\n",
    "# to run, and rerunning this cell before rerunning _run() below is a valid way of running multiple experiments\n",
    "# \n",
    "# If you wish to run this with paramRunner.py, the values here are the default and will be overwritten\n",
    "# by any of them if they are defined in the config .json file supplied to paramRunner.py\n",
    "#\n",
    "# Familiarize yourself with the impact and valid values for each of these values in the classes\n",
    "# Algorithm, Genome, and Population before making modifications, and take a look at\n",
    "# _run() and _initial_population to see the impact of experiment_name\n",
    "\n",
    "experiment_name = 's1_3'\n",
    "population_size = 15\n",
    "sample_strategy = 'tournament_epsilon'\n",
    "epochs = 15\n",
    "iterations = 20\n",
    "batch_size = 200\n",
    "train_sample = 60000\n",
    "test_sample = 10000\n",
    "w_accuracy = 1\n",
    "w_time = -1\n",
    "w_params = -1  #not used in this project and is provided for future reseach and model extension\n",
    "dry_run = False\n",
    "only_time_bound = False # Whether to calculate the time bounds for min and max network only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset into memory in its own cell so that if so desired the algorithm can be\n",
    "# rerun below without needing to reload the dataset.\n",
    "dataset = _mnist_dataset(train_sample = train_sample, test_sample = test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Would have run with')\n",
    "print('experiment-name: ', experiment_name)\n",
    "print('population-size: ', population_size)\n",
    "print('sample-strategy: ', sample_strategy)\n",
    "print('epochs: ', epochs)\n",
    "print('iterations: ', iterations)\n",
    "print('batch-size: ', batch_size)\n",
    "print('train-sample: ', train_sample)\n",
    "print('test-size: ', test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_population = _initialize_population(experiment_name = experiment_name[:4], population_size = population_size)\n",
    "# Initialize weights for the prediction function properly\n",
    "Population.set_weights(w_accuracy=w_accuracy, w_time=w_time, w_params=w_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time stats. This dictionary contains time statistics. More precisely: the key is the sampling strategy. The output is\n",
    "# a list where each index is the iteration. The content is a tuple. element[0] is the mean time. element[1] is the time std\n",
    "global_time_stats = collections.defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if dry_run:\n",
    "    print('Just a dry-run to see config and generate population. Bye')\n",
    "else:\n",
    "    # Initialize folder to dump results\n",
    "    if not os.path.exists('results'):\n",
    "        os.mkdir('results')\n",
    "    _run(initial_population, dataset, sample_strategy = sample_strategy, experiment_name = experiment_name,\n",
    "         epochs = epochs, iterations = iterations, population_size = population_size, batch_size = batch_size,\n",
    "         only_time_bound=only_time_bound)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
